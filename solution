### STEP 1: Configuring Keys

Terraform needs IAM Access and secret access keys in order to connect to AWS and utilize the services. You can either establish a new IAM user or supply a role (we'll be defining an IAM user) and generate the keys for this tutorial. Get the keys by downloading them.

Check the profile for that key when it has been downloaded. The profile will often be [default] and it will be saved in the following directory.

```
cd home/.aws/credentials
```

### STEP 2: Folder Structure

Make two subdirectories called main and modules in the working directory. The modules will hold the individual modules for every service, whereas the main will hold our primary configuration file.



Now, make three files inside the main folder: `terraform.tfvars` to store the variables, and `main.tf` to configure the `modules.tf` for the variables' declaration.

Additionally, each module will have `main.tf` for the variables and module setup.tf to declare the outputs and variables needed in that `module.tf` that are suitable for usage as module variables.

Within the primary directory:

`Main.tf`

```
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 6.0"
    }
  }
}

# Configure the AWS Provider
provider "aws" {
  region = "us-east-1"
}
```
`vpc.tf (VPC + Internet Gateway)`
```
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr_block
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "${var.environment}-vpc"
  }
}

# --- Internet Gateway ---
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "${var.environment}-igw"
  }
}
```

`Subnets.tf (Public & Private Subnets)`
```
resource "aws_subnet" "public" {
  count                   = length(var.availability_zones)
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(var.vpc_cidr_block, 8, count.index) # Example: /24 subnets from a /16 VPC
  availability_zone       = var.availability_zones[count.index]
  map_public_ip_on_launch = true # Required for NAT Gateway in public subnet

  tags = {
    Name = "${var.environment}-public-subnet-${count.index}"
  }
}

# --- Private Subnets (for Tier 2 application instances) ---
resource "aws_subnet" "private" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr_block, 8, count.index + length(var.availability_zones)) # Offset for private subnets
  availability_zone = var.availability_zones[count.index]

  tags = {
    Name = "${var.environment}-private-subnet-${count.index}"
  }
}
```

`Nat.tf (Elastic IPs for NAT Gateways)`
```
resource "aws_eip" "nat" {
  count = length(var.availability_zones)
  vpc   = true # Associate with VPC

  tags = {
    Name = "${var.environment}-nat-eip-${count.index}"
  }
}

# --- NAT Gateways ---
resource "aws_nat_gateway" "main" {
  count         = length(var.availability_zones) # One NAT Gateway per AZ for resilience
  allocation_id = aws_eip.nat[count.index].id
  subnet_id     = aws_subnet.public[count.index].id

  tags = {
    Name = "${var.environment}-nat-gateway-${count.index}"
  }
}
```

`routing.tf (Route Tables & Associations)`
```
# --- Route Table for Public Subnets ---
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
}

# --- Associate Public Subnets with Public Route Table ---
resource "aws_route_table_association" "public" {
  count          = length(aws_subnet.public)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

# --- Route Tables for Private Subnets (each with its own NAT Gateway) ---
resource "aws_route_table" "private" {
  count  = length(var.availability_zones)
  vpc_id = aws_vpc.main.id

  route {
    cidr_block     = "0.0.0.0/0"
    nat_gateway_id = aws_nat_gateway.main[count.index].id
  }
}

# --- Associate Private Subnets with Private Route Tables ---
resource "aws_route_table_association" "private" {
  count          = length(aws_subnet.private)
  subnet_id      = aws_subnet.private[count.index].id
  route_table_id = aws_route_table.private[count.index].id # Each private subnet uses the NAT in its AZ
}
```

`Security_groups.tf`
```
# --- Security Group for Tier 2 Instances ---
resource "aws_security_group" "alb_sg" {
  vpc_id = aws_vpc.main.id

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_security_group" "bastion_sg" {
  vpc_id = aws_vpc.main.id

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["YOUR_OFFICE_IP_CIDR"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_security_group" "tier2_sg" {
  vpc_id = aws_vpc.main.id

  ingress {
    from_port       = 8080
    to_port         = 8080
    protocol        = "tcp"
    security_groups = [aws_security_group.alb_sg.id]
  }

  ingress {
    from_port       = 22
    to_port         = 22
    protocol        = "tcp"
    security_groups = [aws_security_group.bastion_sg.id]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

`ec2_tier2.tf`

```
# --- EC2 Instances for Tier 2 ---
resource "aws_instance" "tier2_app" {
  count         = var.tier2_instance_count
  ami           = data.aws_ami.ubuntu.id
  instance_type = var.tier2_instance_type
  subnet_id     = element(aws_subnet.private[*].id, count.index)
  vpc_security_group_ids = [aws_security_group.tier2_sg.id]
  key_name      = var.ssh_key_pair
  user_data     = file("install_app.sh")

  tags = {
    Name = "${var.environment}-tier2-${count.index}"
  }
}
```


`alb.tf`
```
# --- ALB, Target Group (for Tier 1 to Tier 2 communication) ---
# This part would typically be defined in a "tier1" or "loadbalancer" module,
# but included here for context of how it connects to Tier 2.

resource "aws_lb" "application" {
  name               = "${var.environment}-tier2-alb"
  internal           = true # Internal ALB, accessed from Tier 1 (e.g., public ALB, web servers)
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb_sg.id] # SG for the ALB
  subnets            = aws_subnet.public[*].id # ALBs typically in public subnets (even internal ones)
}

resource "aws_lb_target_group" "tier2_app" {
  name     = "${var.environment}-tier2-app-tg"
  port     = 8080 # Application port
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
  target_type = "instance" # Or "ip" if using Fargate/EKS

  health_check {
    path = "/health" # Your application's health check endpoint
    port = "traffic-port"
    protocol = "HTTP"
    matcher = "200"
  }

  tags = {
    Name = "${var.environment}-tier2-app-tg"
  }
}

resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.application.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.tier2_app.arn
  }
}

resource "aws_lb_target_group_attachment" "tier2_app_attach" {
  count            = var.tier2_instance_count
  target_group_arn = aws_lb_target_group.tier2_app.arn
  target_id        = aws_instance.tier2_app[count.index].id
  port             = 8080
}

# --- Placeholder Security Group for ALB (would be in a separate module/file) ---
resource "aws_security_group" "alb_sg" {
  vpc_id = aws_vpc.main.id
  name   = "${var.environment}-alb-sg"
  description = "Security group for the Application Load Balancer"

  # Example: Allow HTTP from web tier (public ALB) or specific IPs
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"] # Be more restrictive in production
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# --- Placeholder Security Group for Bastion Host (would be in a separate module/file) ---
resource "aws_security_group" "bastion_sg" {
  vpc_id = aws_vpc.main.id
  name   = "${var.environment}-bastion-sg"
  description = "Security group for the Bastion Host"

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["YOUR_OFFICE_IP_CIDR"] # Restrict to known IPs
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

`data.tf`

```
# --- Data Source for latest Ubuntu AMI ---
data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"]

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*"]
  }
}

```

`outputs.tf`
```
# --- Outputs (optional, but good practice) ---
output "vpc_id" {
  value = aws_vpc.main.id
}

output "private_subnets" {
  value = aws_subnet.private[*].id
}

output "tier2_sg" {
  value = aws_security_group.tier2_sg.id
}

```


`install_app.sh`

```
#!/bin/bash
sudo apt update -y
sudo apt install -y nginx # Example: Install Nginx as your app
sudo systemctl start nginx
sudo systemctl enable nginx
echo "<h1>Hello from Tier 2 Application Server!</h1>" | sudo tee /var/www/html/index.nginx-debian.html
```

### Deployment Steps:
Initialize Terraform:
```Bash
terraform init
```

### Review the Plan:
```Bash

terraform plan
```

### Apply the Configuration:
```Bash

terraform apply
```
